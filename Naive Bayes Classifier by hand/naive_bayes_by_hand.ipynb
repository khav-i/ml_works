{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlVC5j9gdd99"
   },
   "source": [
    "# Наивный Байесовский Классификатор для классификации спам-сообщений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный байесовский классификатор by hand\n",
    "\n",
    "### Загрузка библиотек и данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i35VBQfFdd-E"
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import numpy as np # для матричных вычислений\n",
    "import pandas as pd # для анализа и предобработки данных\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # векторизатор\n",
    "from sklearn.metrics import accuracy_score, classification_report # метрики\n",
    "from sklearn.model_selection import train_test_split # сплитование выборки\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB # модели НБК"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл (разделителем здесь выступает символ табуляции)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A1b5QrS5dd-F",
    "outputId": "ad0e2dbf-f406-41ae-8cda-9e043efb2f8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data = pd.read_csv('data/SMSSpamCollection.zip', header=None, sep='\\t', names=['Label', 'SMS'])\n",
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько объектов каждого класса присутствует в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p7_2JzUvdd-G",
    "outputId": "6167fcf9-f386-48cf-b2fe-4ca8012835c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SMS\n",
       "Label      \n",
       "ham    4825\n",
       "spam    747"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQG2a4SVdd-H"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем символы, не являющиеся буквами, приводим тексты SMS к нижнему регистру, разбиваем строки на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T9c0M4vhdd-I"
   },
   "outputs": [],
   "source": [
    "sms_data_clean = sms_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jd-UcYg6dd-I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [go, until, jurong, point, crazy, available, o...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4    [nah, i, don, t, think, he, goes, to, usf, he,...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\W+', ' ', regex=True)\n",
    "\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.lower()\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.split()\n",
    "\n",
    "sms_data_clean['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PZCmBLCLdd-L",
    "outputId": "e37750a2-4124-4733-9bb2-0e7b057e4171",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выводим доли классов в данных\n",
    "sms_data_clean['Label'].value_counts() / sms_data_clean.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50oksBrrdd-L"
   },
   "source": [
    "### Разделение на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сэмплируем\n",
    "train_data = sms_data_clean.sample(frac=0.8, random_state=42)\n",
    "test_data = sms_data_clean.drop(train_data.index)\n",
    "# Сбрасываем индексацию\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WU_YwDxgdd-M",
    "outputId": "d7897ce6-95c9-4be3-f269-5009666c7f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.698071\n",
       "spam    13.301929\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем доли классов в треннировочной выборке\n",
    "train_data['Label'].value_counts() / train_data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B_WG0yuqdd-M",
    "outputId": "c3c9a44e-9ee8-42f4-d6b6-5522898cb267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер треннировочной выборки\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fbrlnUxfdd-N",
    "outputId": "2bdc65d7-0b76-4c28-dae7-d1fe620e6a59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.175943\n",
       "spam    13.824057\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем доли классов в тестовой выборке\n",
    "test_data['Label'].value_counts() / test_data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dHM1P3h2dd-N",
    "outputId": "4b2a0eba-0468-4e7d-e1dd-f091728cdecc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер тестовой выборки\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что и в обучающей, и в тестовой выборке содержится примерно 86-87% спама – как и в нашем оригинальном датасете. Сэмплирование прошло вполне удачно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVmTrhNSdd-O"
   },
   "source": [
    "### Список слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём список всех слов, встречающихся в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ahLFpWI3dd-O"
   },
   "outputs": [],
   "source": [
    "# Объединяем списки слов в сообщениях и проводим\n",
    "# нашу коллекцию через преобразование во множество\n",
    "vocabulary = list(set(train_data['SMS'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eSN6U0QLdd-O",
    "outputId": "5dcb7d6f-900f-483c-e896-4ef69459dced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['irritates',\n",
       " 'laying',\n",
       " 'your',\n",
       " 'pink',\n",
       " 'destiny',\n",
       " 'brings',\n",
       " 'tagged',\n",
       " 'ambrith',\n",
       " 'goodnite']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Образец результата\n",
    "vocabulary[11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MegzBwCFdd-P",
    "outputId": "fa6a956c-5602-4193-8925-6ecb43b5b719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Число итоговых уникальных строк\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs_mok2wdd-P"
   },
   "source": [
    "### Рассчитаем частоты слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого SMS-сообщения посчитаем, сколько раз в нём встречается каждое слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vER-xPhXdd-P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decking</th>\n",
       "      <th>parts</th>\n",
       "      <th>onwards</th>\n",
       "      <th>holiday</th>\n",
       "      <th>fulfil</th>\n",
       "      <th>cat</th>\n",
       "      <th>wasnt</th>\n",
       "      <th>atten</th>\n",
       "      <th>values</th>\n",
       "      <th>predictive</th>\n",
       "      <th>...</th>\n",
       "      <th>shakespeare</th>\n",
       "      <th>latr</th>\n",
       "      <th>city</th>\n",
       "      <th>downstem</th>\n",
       "      <th>impressed</th>\n",
       "      <th>79</th>\n",
       "      <th>quick</th>\n",
       "      <th>postcode</th>\n",
       "      <th>ors</th>\n",
       "      <th>talents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   decking  parts  onwards  holiday  fulfil  cat  wasnt  atten  values  \\\n",
       "0        0      0        0        0       0    0      0      0       0   \n",
       "1        0      0        0        0       0    0      0      0       0   \n",
       "2        0      0        0        0       0    0      0      0       0   \n",
       "3        0      0        0        0       0    0      0      0       0   \n",
       "4        0      0        0        0       0    0      0      0       0   \n",
       "\n",
       "   predictive  ...  shakespeare  latr  city  downstem  impressed  79  quick  \\\n",
       "0           0  ...            0     0     0         0          0   0      0   \n",
       "1           0  ...            0     0     0         0          0   0      0   \n",
       "2           0  ...            0     0     0         0          0   0      0   \n",
       "3           0  ...            0     0     0         0          0   0      0   \n",
       "4           0  ...            0     0     0         0          0   0      0   \n",
       "\n",
       "   postcode  ors  talents  \n",
       "0         0    0        0  \n",
       "1         0    0        0  \n",
       "2         0    0        0  \n",
       "3         0    0        0  \n",
       "4         0    0        0  \n",
       "\n",
       "[5 rows x 7816 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_counts_per_sms = pd.DataFrame([\n",
    "    [row[1].count(word) for word in vocabulary]\n",
    "    for _, row in train_data.iterrows()\n",
    "], columns=vocabulary)\n",
    "\n",
    "word_counts_per_sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим частоты каждого слова в обучающий датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dNc8Juygdd-P"
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, word_counts_per_sms], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FxcXHWgqdd-Q",
    "outputId": "cda89d7c-4596-4dc7-e274-01afb214c54c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>decking</th>\n",
       "      <th>parts</th>\n",
       "      <th>onwards</th>\n",
       "      <th>holiday</th>\n",
       "      <th>fulfil</th>\n",
       "      <th>cat</th>\n",
       "      <th>wasnt</th>\n",
       "      <th>atten</th>\n",
       "      <th>...</th>\n",
       "      <th>shakespeare</th>\n",
       "      <th>latr</th>\n",
       "      <th>city</th>\n",
       "      <th>downstem</th>\n",
       "      <th>impressed</th>\n",
       "      <th>79</th>\n",
       "      <th>quick</th>\n",
       "      <th>postcode</th>\n",
       "      <th>ors</th>\n",
       "      <th>talents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[squeeeeeze, this, is, christmas, hug, if, u, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[and, also, i, ve, sorta, blown, him, off, a, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[mmm, thats, better, now, i, got, a, roast, do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  decking  parts  \\\n",
       "0   ham  [squeeeeeze, this, is, christmas, hug, if, u, ...        0      0   \n",
       "1   ham  [and, also, i, ve, sorta, blown, him, off, a, ...        0      0   \n",
       "2   ham  [mmm, thats, better, now, i, got, a, roast, do...        0      0   \n",
       "\n",
       "   onwards  holiday  fulfil  cat  wasnt  atten  ...  shakespeare  latr  city  \\\n",
       "0        0        0       0    0      0      0  ...            0     0     0   \n",
       "1        0        0       0    0      0      0  ...            0     0     0   \n",
       "2        0        0       0    0      0      0  ...            0     0     0   \n",
       "\n",
       "   downstem  impressed  79  quick  postcode  ors  talents  \n",
       "0         0          0   0      0         0    0        0  \n",
       "1         0          0   0      0         0    0        0  \n",
       "2         0          0   0      0         0    0        0  \n",
       "\n",
       "[3 rows x 7818 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экскурс в теорию\n",
    "\n",
    "Наивный байесовский классификатор (НБК, англ. Naive Bayes Classifier, NBC) решает задачу классификации объектов по типам. Большим преимуществом этого алгоритма является его простота, как идейная, так и алгоритмическая.\n",
    "\n",
    "Наивная байесовская классификация — это достаточно простой вероятностный алгоритм, основанный на том, что все признаки модели независимы.\n",
    "\n",
    "Если, например, мы говорим про задачу классификации спам-писем и обычных писем, то в этом контексте мы считаем, что каждое слово в сообщении не зависит от всех других слов, то есть каждое слово мы учитываем, не обращая внимания на контекст.\n",
    "\n",
    "Алгоритм классификации выдаёт вероятность того, является письмо спамом или нет, основываясь на наборе слов в письме. Расчёт этой вероятности основан на формуле Байеса, а компоненты формулы рассчитываются на основе частот слов во всём наборе сообщений.\n",
    "\n",
    "Прежде всего, возьмём формулу Байеса и применим её к нашей задаче:\n",
    "\n",
    "$$P(Спам|w_1, w_2, ..., w_n) \\propto P(Спам) \\cdot \\displaystyle\\prod_{i=1}^{n} P(w_i | Спам)$$\n",
    "\n",
    "Вероятность того, что письмо является спамом при условии, что в нём есть определённые слова (которые мы обозначили), пропорциональна произведению двух значений:\n",
    " - вероятности получения спама в целом (по сути, это доля спама в выборке);\n",
    " - произведения вероятностей, что в письме есть некоторое слово $w_i$, если письмо является спамом, для всех слов выборки.\n",
    "\n",
    "Разберёмся с этим подробнее. Для каждого слова в сообщении мы рассчитываем вероятность того, что это слово окажется в спаме. В рамках нашей задачи рассматриваем следующие значения:\n",
    " - $P(spam)$ — вероятность, что случайно взятое письмо будет спамом (также это доля спам-сообщений в нашем наборе данных);\n",
    " - $P(w_i | spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо является спамом.\n",
    "\n",
    "По той же логике можем определить:\n",
    " - $P(not spam)$ — доля сообщений, которые не являются спамом;\n",
    " - $P(w_i | not spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо не является спамом.\n",
    "\n",
    "Теперь необходимо понять, как рассчитать вероятности каждого слова. Для этого в алгоритме используется следующая формула:\n",
    "\n",
    "$$P(w_i | spam)=\\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "В этой формуле:\n",
    " - $N_{Vocabulary}$ — количество уникальных слов во всём наборе данных;\n",
    " - $N_{Spam}$ — общее количество слов в спам-сообщениях;\n",
    " - $N_{w_i|Spam}$ — количество повторов слова во всех спам-сообщениях;\n",
    " - $\\alpha$ — коэффициент для случаев, когда слово в сообщении отсутствует в нашем наборе данных.\n",
    "\n",
    "Кратко это можно объяснить так: вероятность того, что это слово встретится в спам сообщении, — это частота этого слова в «спамовой части» нашего набора данных (но с добавлением «сглаживания», чтобы учитывать ситуации, когда попадаются слова, которых не было в обучающей выборке).\n",
    "\n",
    "Также эта же формула (но с другими значениями) верна для вероятности того, что слово принадлежит не спам-сообщениям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Значения для формулы Байеса\n",
    "\n",
    "Посчитаем необходимые значения для формулы Байеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IwxBHjXYdd-Q"
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "Nvoc = len(vocabulary)\n",
    "Pspam = train_data['Label'].value_counts()['spam'] / train_data.shape[0]\n",
    "Pham = train_data['Label'].value_counts()['ham'] / train_data.shape[0]\n",
    "Nspam = train_data.loc[train_data['Label'] == 'spam', 'SMS'].apply(len).sum()\n",
    "Nham = train_data.loc[train_data['Label'] == 'ham', 'SMS'].apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jde0BGdPdd-R"
   },
   "outputs": [],
   "source": [
    "def p_w_spam(word):\n",
    "    \"\"\"\n",
    "    Функция для расчета вероятности присутствия слова в спаме.\n",
    "    \"\"\"\n",
    "    if word in train_data.columns:\n",
    "        return (train_data.loc[train_data['Label'] == 'spam', word].sum() + alpha) / (Nspam + alpha*Nvoc)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def p_w_ham(word):\n",
    "    \"\"\"\n",
    "    Функция для расчета вероятности присутствия слова в письме.\n",
    "    \"\"\"\n",
    "    if word in train_data.columns:\n",
    "        return (train_data.loc[train_data['Label'] == 'ham', word].sum() + alpha) / (Nham + alpha*Nvoc)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-nPavNOdd-S"
   },
   "source": [
    "### Готовим алгоритм классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ib39OrM8dd-S"
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \"\"\"\n",
    "    Функция-классификатор письма на основе рассчитанных вероятностей.\n",
    "    \"\"\"\n",
    "    p_spam_given_message = Pspam\n",
    "    p_ham_given_message = Pham\n",
    "    for word in message:\n",
    "        p_spam_given_message *= p_w_spam(word)\n",
    "        p_ham_given_message *= p_w_ham(word)\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QECGrw8dd-S"
   },
   "source": [
    "### Используем тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dNWXV-5odd-S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data['predicted'] = test_data['SMS'].map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AejY85XOdd-S",
    "outputId": "112fe436-4d36-42a6-8d3d-8952e282939c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[had, your, mobile, 11, months, or, more, u, r...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[oh, k, i, m, watching, here]</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  [u, dun, say, so, early, hor, u, c, already, t...       ham\n",
       "1   ham  [nah, i, don, t, think, he, goes, to, usf, he,...       ham\n",
       "2  spam  [freemsg, hey, there, darling, it, s, been, 3,...       ham\n",
       "3  spam  [had, your, mobile, 11, months, or, more, u, r...      spam\n",
       "4   ham                      [oh, k, i, m, watching, here]       ham"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lNHidizgdd-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильных предсказаний 98.384201 %\n"
     ]
    }
   ],
   "source": [
    "correct = (test_data['predicted'] == test_data['Label']).sum() / test_data.shape[0]\n",
    "print(f\"Правильных предсказаний {correct * 100:3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-s5NRlJGdd-T",
    "outputId": "de7985cf-9878-486c-ff7a-54295961199e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ham</td>\n",
       "      <td>[waiting, for, your, call]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ham</td>\n",
       "      <td>[26th, of, july]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>spam</td>\n",
       "      <td>[sms, ac, jsco, energy, is, high, but, u, may,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>spam</td>\n",
       "      <td>[this, message, is, brought, to, you, by, gmw,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>spam</td>\n",
       "      <td>[how, come, it, takes, so, little, time, for, ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>spam</td>\n",
       "      <td>[do, you, ever, notice, that, when, you, re, d...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>spam</td>\n",
       "      <td>[rct, thnq, adrian, for, u, text, rgds, vatian]</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>spam</td>\n",
       "      <td>[life, has, never, been, this, much, fun, and,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>ham</td>\n",
       "      <td>[wiskey, brandy, rum, gin, beer, vodka, scotch...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>spam</td>\n",
       "      <td>[xmas, new, years, eve, tickets, are, now, on,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>ham</td>\n",
       "      <td>[unlimited, texts, limited, minutes]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>spam</td>\n",
       "      <td>[accordingly, i, repeat, just, text, the, word...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>spam</td>\n",
       "      <td>[thesmszone, com, lets, you, send, free, anony...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>spam</td>\n",
       "      <td>[money, i, have, won, wining, number, 946, wot...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nokia, phone, is, lovly]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>spam</td>\n",
       "      <td>[dating, i, have, had, two, of, these, only, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>spam</td>\n",
       "      <td>[latest, news, police, station, toilet, stolen...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "2     spam  [freemsg, hey, there, darling, it, s, been, 3,...       ham\n",
       "96     ham                         [waiting, for, your, call]      spam\n",
       "182    ham                                   [26th, of, july]      spam\n",
       "269   spam  [sms, ac, jsco, energy, is, high, but, u, may,...       ham\n",
       "479   spam  [this, message, is, brought, to, you, by, gmw,...       ham\n",
       "528   spam  [how, come, it, takes, so, little, time, for, ...       ham\n",
       "576   spam  [do, you, ever, notice, that, when, you, re, d...       ham\n",
       "652   spam    [rct, thnq, adrian, for, u, text, rgds, vatian]       ham\n",
       "679   spam  [life, has, never, been, this, much, fun, and,...       ham\n",
       "687    ham  [wiskey, brandy, rum, gin, beer, vodka, scotch...      spam\n",
       "711   spam  [xmas, new, years, eve, tickets, are, now, on,...       ham\n",
       "775    ham               [unlimited, texts, limited, minutes]      spam\n",
       "846   spam  [accordingly, i, repeat, just, text, the, word...       ham\n",
       "855   spam  [thesmszone, com, lets, you, send, free, anony...       ham\n",
       "891   spam  [money, i, have, won, wining, number, 946, wot...       ham\n",
       "962    ham                          [nokia, phone, is, lovly]      spam\n",
       "1073  spam  [dating, i, have, had, two, of, these, only, s...       ham\n",
       "1085  spam  [latest, news, police, station, toilet, stolen...       ham"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем список сообщений (их немного) с неверной классификацией\n",
    "test_data.loc[test_data['predicted'] != test_data['Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем все метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.987     0.995     0.991       960\n",
      "        spam      0.966     0.916     0.940       154\n",
      "\n",
      "    accuracy                          0.984      1114\n",
      "   macro avg      0.976     0.955     0.965      1114\n",
      "weighted avg      0.984     0.984     0.984      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_classify_pred = test_data['predicted']\n",
    "y_test = test_data['Label']\n",
    "\n",
    "# Вывод отчета о метриках тестовой выборки\n",
    "print(classification_report(y_test, y_test_classify_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный байесовский классификатор в sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, мы реализовали наивный байесовский классификатор с нуля!\n",
    "А теперь посмотрим, как то же самое можно сделать с помощью библиотеки scikit-learn.\n",
    "\n",
    "### Загрузка и предобработка данных\n",
    "\n",
    "Прочитаем заново csv-файл и предобработаем данные. Разбивать сообщения на слова в этот раз не нужно, мы сделаем это далее с помощью встроенных инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i don t think he goes to usf he lives arou..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/SMSSpamCollection.zip\", header=None, sep=\"\\t\", names=[\"Label\", \"SMS\"]\n",
    ")\n",
    "\n",
    "# Также предобработаем содержимое сообщений\n",
    "df[\"SMS\"] = df[\"SMS\"].str.replace(r\"\\W+\", \" \", regex=True).str.lower()\n",
    "df['SMS'] = df['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "df['SMS'] = df['SMS'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация и сплитование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем строки в векторный вид – то есть, снова создадим таблицу с частотами слов. Но в этот раз воспользуемся встроенным в sklearn классом CountVectorizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8713) (5572,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"SMS\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любопытно: в этот раз число столбцов больше почти на тысячу. CountVectorizer не настолько прост, как наш ручной алгоритм.\n",
    "\n",
    "С помощью функции `train_test_split` из scikit-learn разобьём выборку на обучающую и тестовую в пропорции 80/20. И здесь мы уже можем прописать стратификацию явно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn есть два подходящих нам байесовских классификатора:\n",
    " - MultinomialNB  — работает с категориальными признаками, текстами и несбалансированными выборками;\n",
    " - ComplementNB — улучшенная версия MultinomialNB, стабильно показывает более высокое качество в задачах классификации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.995     0.997     0.996      3859\n",
      "        spam      0.980     0.968     0.974       598\n",
      "\n",
      "    accuracy                          0.993      4457\n",
      "   macro avg      0.987     0.983     0.985      4457\n",
      "weighted avg      0.993     0.993     0.993      4457\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.992     0.984     0.988       966\n",
      "        spam      0.904     0.946     0.925       149\n",
      "\n",
      "    accuracy                          0.979      1115\n",
      "   macro avg      0.948     0.965     0.956      1115\n",
      "weighted avg      0.980     0.979     0.980      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем объект MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "# Обучим\n",
    "mnb.fit(X_train, y_train)\n",
    "# Сделаем предсказания классов объектов в обоих выборках\n",
    "y_train_mnb_pred = mnb.predict(X_train)\n",
    "y_test_mnb_pred = mnb.predict(X_test)\n",
    "\n",
    "# Вывод отчета о метриках треннировочной выборки\n",
    "print(classification_report(y_train, y_train_mnb_pred, digits=3))\n",
    "\n",
    "# Вывод отчета о метриках тестовой выборки\n",
    "print(classification_report(y_test, y_test_mnb_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.996     0.989     0.992      3859\n",
      "        spam      0.930     0.973     0.951       598\n",
      "\n",
      "    accuracy                          0.987      4457\n",
      "   macro avg      0.963     0.981     0.972      4457\n",
      "weighted avg      0.987     0.987     0.987      4457\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.995     0.969     0.982       966\n",
      "        spam      0.828     0.966     0.892       149\n",
      "\n",
      "    accuracy                          0.969      1115\n",
      "   macro avg      0.911     0.968     0.937      1115\n",
      "weighted avg      0.972     0.969     0.970      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем объект MultinomialNB\n",
    "cnb = ComplementNB()\n",
    "# Обучим\n",
    "cnb.fit(X_train, y_train)\n",
    "# Сделаем предсказания классов объектов в обоих выборках\n",
    "y_train_cnb_pred = cnb.predict(X_train)\n",
    "y_test_cnb_pred = cnb.predict(X_test)\n",
    "\n",
    "# Вывод отчета о метриках треннировочной выборки\n",
    "print(classification_report(y_train, y_train_cnb_pred, digits=3))\n",
    "\n",
    "# Вывод отчета о метриках тестовой выборки\n",
    "print(classification_report(y_test, y_test_cnb_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш ручной алгоритм наивного байесовского классификатора справился с задачей весьма неплохо. Даже больше – он показал себя лучше, чем библиотечные модели с дефолтными параметрами. Однако последние мы еще можем оптимизировать, но это мы сделаем в следующий раз."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "НаивныйБайес.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86c56a74836ad344b00594bf6f38fa6a676a207ceefe20d101fbc465800ccb8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
