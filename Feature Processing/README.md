# Обработка признаков на примере датасета продаж автомобилей Ford

В этой работе мы займемся обработкой и подбором признаков датасета для повышения качества обучаемых моделей.
Нам предстоит избавиться от пропусков в данных, произвести кодирование, масштабирование и отбор признаков с помощью специальных методов.
Процесс обработки мы будем сопровождать обучением модели на промежуточных данных, чтобы оценить влияние обработки 
на значения получающихся метрик (R2, MAE).

# Содержание

1. Загрузка и знакомство с данными
2. Baseline model
3. Заполнение пропусков с помощью ML
4. Кодирование признаков
5. Геоданные
6. Преобразование признаков
7. Отбор признаков
 * Анализ корреляций
 * Метод рекурсивного исключения признаков
 * Метод выбора признаков на основе фильтров
 * Обучение моделей
8. Вывод

# Результат
Лучше всего себя показала базовая модель.

![image](https://github.com/khav-i/ml_works/assets/126453765/f401e984-5103-4791-93c6-47467f572ad5)

# Вывод

Нет сомнений, что мы можем перепрыгнуть нашу базовую модель, попытавшись использовать, например, алгоритм регрессии на градиентном
спуске или полиномиальную регрессию, однако целью данной работы было именно рассмотрение методов предобработки данных.
Да, наше их использование не очень хорошо отразилось на качестве модели, но в этом, скорее всего, нет вины самих методов:
возможно, в этом плане наш выбор ml-алгоритма был неудачен, а возможно, нам просто не хватило времени, чтобы более вдумчиво
использовать методы предобработки (было потрачено три дня неспешных манипуляций с кодом).

По результатам этот труд, боюсь, неудачен, а ценным является лишь сопутствовавший экспириенс автора, непосредственно измерить
который никому из третьих лиц, вероятнее всего, не удастся (:

# [Ссылка на ноутбук с кодом](https://github.com/khav-i/ml_works/blob/master/Feature%20Processing/feature_processing.ipynb)
