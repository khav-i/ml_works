{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Исследование данных Samsung. Классификация физической активности пользователей\n",
    "\n",
    "В этой работе мы продолжим наше исследование данных, взятых с датчиков акселерометров и гироскопов смартфонов Samsung Galaxy S3. Телефоны носили в кармане добровольцы в возрасте от 19 до 49 лет. Смартфоны постоянно фиксировали значения ускорения и скорости по трём измерениям, а поведение людей записывали на видео, чтобы вручную отметить, какую физическую активность осуществлял человек в тот или иной момент.\n",
    "\n",
    "Данные содержат следующие признаки:\n",
    "* различные показатели с акселерометра и гироскопа;\n",
    "* метка активности (физическая активность человека в конкретный момент).\n",
    "\n",
    "Попробуем на основе данных с гироскопа и акселерометра разделить активности людей на некоторые схожие по своим характеристикам группы с помощью алогиритмов классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import multioutput\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn import metrics\n",
    "# Для оптимизации моделей\n",
    "import optuna\n",
    "# Для графики и отображения\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "# Подавление варнов\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число наблюдений в трейне: 7352\n",
      "Число наблюдений в тесте:  2947\n",
      "Число фич: 561\n"
     ]
    }
   ],
   "source": [
    "X_train = np.loadtxt(\"data/train.txt\")\n",
    "y_train = np.loadtxt(\"data/train_labels.txt\")\n",
    " \n",
    "X_test = np.loadtxt(\"data/test.txt\")\n",
    "y_test = np.loadtxt(\"data/test_labels.txt\")\n",
    "\n",
    "print(f'Число наблюдений в трейне: {X_train.shape[0]}')\n",
    "print(f'Число наблюдений в тесте:  {X_test.shape[0]}')\n",
    "print(f'Число фич: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем также число различных активностей — сколько наблюдений должны быть отнесены каждому классу в трейне и в тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список лейблов целевой переменной:  [1, 2, 3, 4, 5, 6]\n",
      "Список размеров истинных кластеров в трейне: [1226, 1073, 986, 1286, 1374, 1407]\n",
      "Список размеров истинных кластеров в тесте: [496, 471, 420, 491, 532, 537]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Список лейблов целевой переменной: ',\n",
    "    list(map(int, list(np.unique(y_train, return_counts=True)[0])))\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Список размеров истинных кластеров в трейне:',\n",
    "    list(np.unique(y_train, return_counts=True)[1])\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Список размеров истинных кластеров в тесте:',\n",
    "    list(np.unique(y_test, return_counts=True)[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, есть ряд активностей, обозначенных цифрами. Эти метки означают следующее:\n",
    "\n",
    "- 1 — ходьба;\n",
    "- 2 — подъём;\n",
    "- 3 — спуск;\n",
    "- 4 — сидение;\n",
    "- 5 — стояние;\n",
    "- 6 — лежание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо отмасштабировать признаки. Будем использовать для этого алгоритм StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем корреляцию, рассчитаем ранг и определитель матрицы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число столбцов: 561\n",
      "Ранг матрицы:   470\n",
      "Определитель:   0.0\n"
     ]
    }
   ],
   "source": [
    "# Матрица корреляций\n",
    "X_corr = np.corrcoef(X_train_norm.T)\n",
    "# Параметры матрицы\n",
    "print('Число столбцов:', X_corr.shape[1])\n",
    "print('Ранг матрицы:  ', np.linalg.matrix_rank(X_corr))\n",
    "print('Определитель:  ', np.linalg.det(X_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понизим размерность данных с помощью метода главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число компонент: 372\n",
      "Число столбцов: 372\n",
      "Ранг матрицы:   372\n",
      "Определитель:   0.9999999999999873\n"
     ]
    }
   ],
   "source": [
    "# Определяем метод таким образом, чтобы отобранные им\n",
    "# компоненты объясняли не менее 99.99 % разброса данных\n",
    "pca = decomposition.PCA(n_components=0.9999)\n",
    "# Преобразуем данные\n",
    "X_train_pca = pca.fit_transform(X_train_norm)\n",
    "X_test_pca = pca.transform(X_test_norm)\n",
    "print(f'Число компонент: {len(X_train_pca[0])}')\n",
    "# Матрица корреляций\n",
    "corr_X_pca = np.corrcoef(X_train_pca.T)\n",
    "# Параметры матрицы\n",
    "print('Число столбцов:', corr_X_pca.shape[1])\n",
    "print('Ранг матрицы:  ', np.linalg.matrix_rank(corr_X_pca))\n",
    "print('Определитель:  ', np.linalg.det(corr_X_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось несколько уменьшить число признаков.\n",
    "\n",
    "Объединим выборки для кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train_pca, X_test_pca))\n",
    "y = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем одну полезную функцию\n",
    "def metrics_extraction(preds_train, preds_test, train_y, test_y):\n",
    "    \"\"\"\n",
    "    Функция для получения массива значений метрик для\n",
    "    их дальнейшей печати и предачи в сводную таблицу.\n",
    "    Args:\n",
    "        preds_train (np.array): вектор предсказанных значений train-выборки;\n",
    "        preds_test (np.array): вектор предсказанных значений test-выборки;\n",
    "        train_y (np.array): вектор истинных значений train-выборки;\n",
    "        test_y (np.array): вектор истинных значений test-выборки.\n",
    "    Returns:\n",
    "        tuple: \n",
    "            list: список строк для вывода метрик треннировочной выборки,\n",
    "            list: список строк для вывода метрик тествовой выборки,\n",
    "            array: вектор метрик треннировочной выборки,\n",
    "            array: вектор метрик тествовой выборки.\n",
    "    \"\"\"\n",
    "    \n",
    "    precision_train = metrics.precision_score(train_y, preds_train, average='weighted')\n",
    "    precision_test = metrics.precision_score(test_y, preds_test, average='weighted')\n",
    "    recall_train = metrics.recall_score(train_y, preds_train, average='weighted')\n",
    "    recall_test = metrics.recall_score(test_y, preds_test, average='weighted')\n",
    "    f1_train = metrics.f1_score(train_y, preds_train, average='weighted')\n",
    "    f1_test = metrics.f1_score(test_y, preds_test, average='weighted')\n",
    "    accuracy_train = metrics.accuracy_score(train_y, preds_train)\n",
    "    accuracy_test = metrics.accuracy_score(test_y, preds_test)\n",
    "    \n",
    "    train_print_lst = [\n",
    "        'Train aggregate metrics:',\n",
    "        f'Precision: {round(precision_train, 4)}',\n",
    "        f'Recall:    {round(recall_train, 4)}',\n",
    "        f'F1 score:  {round(f1_train, 4)}',\n",
    "        f'Accuracy:  {round(accuracy_train, 4)}'\n",
    "    ]\n",
    "    \n",
    "    test_print_lst = [\n",
    "        'Test aggregate metrics:',\n",
    "        f'Precision: {round(precision_test, 4)}',\n",
    "        f'Recall:    {round(recall_test, 4)}',\n",
    "        f'F1 score:  {round(f1_test, 4)}',\n",
    "        f'Accuracy:  {round(accuracy_test, 4)}'\n",
    "    ]\n",
    "    \n",
    "    train_array = np.array([\n",
    "        precision_train, recall_train, f1_train, accuracy_train\n",
    "    ])\n",
    "    \n",
    "    test_array = np.array([\n",
    "        precision_test, recall_test, f1_test, accuracy_test\n",
    "    ])\n",
    "    \n",
    "    return train_print_lst, test_print_lst, train_array, test_array\n",
    "\n",
    "\n",
    "def cv_scores(model, X, y, cv=10):\n",
    "    \"\"\"\n",
    "    Функция кросс-валидации модели.\n",
    "    Args:\n",
    "        model: объект, который будет обучаться на данных;\n",
    "        X (np.array): матрица данных;\n",
    "        y (np.array): вектор целевой переменной;\n",
    "        cv (int, cross-validation generator):\n",
    "            число фолдов кросс-валидации, либо cross-validation estimator.\n",
    "    Returns:\n",
    "        None\n",
    "        prints:\n",
    "           Train scores: precision, recall, f1_weighted.\n",
    "           Test scores: precision, recall, f1_weighted.\n",
    "    \"\"\"\n",
    "    scores = model_selection.cross_validate(\n",
    "        model, X, y, cv=cv,\n",
    "        scoring=('precision_weighted', 'recall_weighted', 'f1_weighted', 'accuracy'),\n",
    "        return_train_score=True\n",
    "    )\n",
    "    print('Train scores:')\n",
    "    print('Precision:  ', round(np.mean(scores['train_precision_weighted']), 4))\n",
    "    print('Recall:     ', round(np.mean(scores['train_recall_weighted']), 4))\n",
    "    print('F1 weighted:', round(np.mean(scores['train_f1_weighted']), 4))\n",
    "    print('Accuracy:   ', round(np.mean(scores['train_accuracy']), 4))\n",
    "    print('Test scores:')\n",
    "    print('Precision:  ', round(np.mean(scores['test_precision_weighted']), 4))\n",
    "    print('Recall:     ', round(np.mean(scores['test_recall_weighted']), 4))\n",
    "    print('F1 weighted:', round(np.mean(scores['test_f1_weighted']), 4))\n",
    "    print('Accuracy:   ', round(np.mean(scores['test_accuracy']), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9464\n",
      "Recall:    0.9464\n",
      "F1 score:  0.9462\n",
      "Accuracy:  0.9464\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9556    0.9536    0.9546       496\n",
      "         2.0     0.9273    0.9745    0.9503       471\n",
      "         3.0     0.9296    0.8810    0.9046       420\n",
      "         4.0     0.9318    0.9185    0.9251       491\n",
      "         5.0     0.9330    0.9417    0.9373       532\n",
      "         6.0     0.9944    0.9963    0.9953       537\n",
      "\n",
      "    accuracy                         0.9464      2947\n",
      "   macro avg     0.9453    0.9443    0.9446      2947\n",
      "weighted avg     0.9464    0.9464    0.9462      2947\n",
      "\n",
      "CPU times: total: 17min 50s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Инициализация объекта\n",
    "cbc = cb.CatBoostClassifier(\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "cbc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_cbc = cbc.predict(X_train_pca)\n",
    "preds_test_cbc = cbc.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_cbc, test_print_cbc, train_array_cbc, test_array_cbc = metrics_extraction(\n",
    "    preds_train_cbc, preds_test_cbc, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_cbc, '-'*25, sep='\\n')\n",
    "print(*test_print_cbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_cbc, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наличествует переобучение, но результаты уже весьма хорошие. Посмотрим, сможем ли мы их улучшить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'penalty': 'l2', 'C': 0.7630868925337111, 'solver': 'newton-cholesky'}\n",
      "f1_score на обучающем наборе: 0.9463\n",
      "\n",
      "Train aggregate metrics:\n",
      "Precision: 0.9942\n",
      "Recall:    0.9942\n",
      "F1 score:  0.9942\n",
      "Accuracy:  0.9942\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9658\n",
      "Recall:    0.9654\n",
      "F1 score:  0.9653\n",
      "Accuracy:  0.9654\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9779    0.9798    0.9789       496\n",
      "         2.0     0.9684    0.9745    0.9714       471\n",
      "         3.0     0.9833    0.9786    0.9809       420\n",
      "         4.0     0.9585    0.8941    0.9252       491\n",
      "         5.0     0.9144    0.9643    0.9387       532\n",
      "         6.0     0.9963    1.0000    0.9981       537\n",
      "\n",
      "    accuracy                         0.9654      2947\n",
      "   macro avg     0.9665    0.9652    0.9655      2947\n",
      "weighted avg     0.9658    0.9654    0.9653      2947\n",
      "\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Напишем функцию для оптимизации\n",
    "def optuna_LogR(trial):\n",
    "    \"\"\"Функция, обучающая модель LogisticRegression по переданным гиперпараметрам\n",
    "    Args:\n",
    "        trial : класс, от которого вызываются гиперпараметры\n",
    "    Returns:\n",
    "        score(float): метрика F1\n",
    "    \"\"\"\n",
    "    # Задаем пространство поиска гиперпараметров\n",
    "    params = {\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2', None]),\n",
    "        'C': trial.suggest_float('C', 0.1, 1),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'newton-cg', 'newton-cholesky'])\n",
    "    }\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = linear_model.LogisticRegression(\n",
    "        **params,\n",
    "        max_iter=3000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Рассчитываем метрику на кросс-валидации\n",
    "    score = model_selection.cross_val_score(\n",
    "        model, X_train_pca, y_train, cv=10, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "    return score\n",
    "\n",
    "# Создаем объект исследования для первого набора гиперпараметров\n",
    "# Укажем, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_LogR = optuna.create_study(study_name=\"LogR_opt\", direction=\"maximize\",)\n",
    "# Подавляем логирование\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_LogR.optimize(optuna_LogR, n_trials=20)\n",
    "\n",
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "LogR_opt = linear_model.LogisticRegression(\n",
    "    **study_LogR.best_params,\n",
    "    max_iter=3000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Обучение\n",
    "LogR_opt.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_LogR_opt = LogR_opt.predict(X_train_pca)\n",
    "preds_test_LogR_opt = LogR_opt.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_LogR, test_print_LogR, train_array_LogR, test_array_LogR = metrics_extraction(\n",
    "    preds_train_LogR_opt, preds_test_LogR_opt, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(f'Лучшие гиперпараметры: {study_LogR.best_params}')\n",
    "print(\"f1_score на обучающем наборе: {:.4f}\\n\".format(study_LogR.best_value))\n",
    "print(*train_print_LogR, '-'*25, sep='\\n')\n",
    "print(*test_print_LogR, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_LogR_opt, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем запустить логистическую регрессию без оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9951\n",
      "Recall:    0.9951\n",
      "F1 score:  0.9951\n",
      "Accuracy:  0.9951\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9659\n",
      "Recall:    0.9654\n",
      "F1 score:  0.9653\n",
      "Accuracy:  0.9654\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9779    0.9798    0.9789       496\n",
      "         2.0     0.9684    0.9745    0.9714       471\n",
      "         3.0     0.9833    0.9786    0.9809       420\n",
      "         4.0     0.9605    0.8921    0.9250       491\n",
      "         5.0     0.9130    0.9662    0.9388       532\n",
      "         6.0     0.9963    1.0000    0.9981       537\n",
      "\n",
      "    accuracy                         0.9654      2947\n",
      "   macro avg     0.9665    0.9652    0.9655      2947\n",
      "weighted avg     0.9659    0.9654    0.9653      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "logr = linear_model.LogisticRegression(\n",
    "    solver='newton-cholesky',\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "logr.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_logr = logr.predict(X_train_pca)\n",
    "preds_test_logr = logr.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_logr, test_print_logr, train_array_logr, test_array_logr = metrics_extraction(\n",
    "    preds_train_logr, preds_test_logr, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_logr, '-'*25, sep='\\n')\n",
    "print(*test_print_logr, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_logr, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ходьба</th>\n",
       "      <th>подъём</th>\n",
       "      <th>спуск</th>\n",
       "      <th>сидение</th>\n",
       "      <th>стояние</th>\n",
       "      <th>лежание</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ходьба</th>\n",
       "      <td>486</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>подъём</th>\n",
       "      <td>10</td>\n",
       "      <td>459</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>спуск</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сидение</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>стояние</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>лежание</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ходьба  подъём  спуск  сидение  стояние  лежание\n",
       "ходьба      486       5      5        0        0        0\n",
       "подъём       10     459      2        0        0        0\n",
       "спуск         1       8    411        0        0        0\n",
       "сидение       0       2      0      440       47        2\n",
       "стояние       0       0      0       19      513        0\n",
       "лежание       0       0      0        0        0      537"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаём таблицу сопряжённости\n",
    "ct = pd.crosstab(y_test, preds_test_LogR_opt)\n",
    "# определяем название активностей\n",
    "ct.index = ['ходьба', 'подъём', \n",
    "            'спуск', 'сидение',\n",
    "            'стояние', 'лежание'\n",
    "]\n",
    "ct.columns = list(ct.index)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуй, можно уже заключить, что наша модель на основе логистической регрессии неплохо справилась с задачей и даже преодолела базовую (удивительный случай, т.к. дефолтный классификатор Catboost часто показывает лучший результат). Для оптимизации ошибки выбран метод Ньютона-Холецкого, мы также наблюдаем переобучение почти на три процента по всем агрегированным метрикам. Автоматический поиск оптимальной комбинации гиперпараметров не сильно улучшил результат.\n",
    "\n",
    "Также стоит отметить распределение ошибок на таблице сопряженности: как и в случае кластеризации, мы видим почти четкое разделение на активные и пассивные действия — за исключением аномалии в виде отнесения двух \"сидений\" к классу \"подъемов\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9917\n",
      "Recall:    0.9917\n",
      "F1 score:  0.9917\n",
      "Accuracy:  0.9917\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9578\n",
      "Recall:    0.9559\n",
      "F1 score:  0.956\n",
      "Accuracy:  0.9559\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9698    0.9698    0.9698       496\n",
      "         2.0     0.9701    0.9660    0.9681       471\n",
      "         3.0     0.9858    0.9929    0.9893       420\n",
      "         4.0     0.9596    0.8697    0.9124       491\n",
      "         5.0     0.8735    0.9737    0.9209       532\n",
      "         6.0     0.9962    0.9665    0.9811       537\n",
      "\n",
      "    accuracy                         0.9559      2947\n",
      "   macro avg     0.9592    0.9564    0.9569      2947\n",
      "weighted avg     0.9578    0.9559    0.9560      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pac = linear_model.PassiveAggressiveClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "pac.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_pac = pac.predict(X_train_pca)\n",
    "preds_test_pac = pac.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_pac, test_print_pac, train_array_pac, test_array_pac = metrics_extraction(\n",
    "    preds_train_pac, preds_test_pac, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_pac, '-'*25, sep='\\n')\n",
    "print(*test_print_pac, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_pac, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейные алгоритмы, похоже, в целом неплохо справляются с задачей — по сравнению с дефолтным Catboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9901\n",
      "Recall:    0.9898\n",
      "F1 score:  0.9898\n",
      "Accuracy:  0.9898\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9554\n",
      "Recall:    0.9522\n",
      "F1 score:  0.9522\n",
      "Accuracy:  0.9522\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9917    0.9657    0.9785       496\n",
      "         2.0     0.9749    0.9894    0.9821       471\n",
      "         3.0     0.9834    0.9881    0.9857       420\n",
      "         4.0     0.9532    0.8289    0.8867       491\n",
      "         5.0     0.8450    0.9737    0.9048       532\n",
      "         6.0     0.9943    0.9702    0.9821       537\n",
      "\n",
      "    accuracy                         0.9522      2947\n",
      "   macro avg     0.9571    0.9527    0.9533      2947\n",
      "weighted avg     0.9554    0.9522    0.9522      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pcn = linear_model.Perceptron(\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "pcn.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_pcn = pcn.predict(X_train_pca)\n",
    "preds_test_pcn = pcn.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_pcn, test_print_pcn, train_array_pcn, test_array_pcn = metrics_extraction(\n",
    "    preds_train_pcn, preds_test_pcn, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_pcn, '-'*25, sep='\\n')\n",
    "print(*test_print_pcn, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_pcn, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9826\n",
      "Recall:    0.9826\n",
      "F1 score:  0.9826\n",
      "Accuracy:  0.9826\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9628\n",
      "Recall:    0.961\n",
      "F1 score:  0.9612\n",
      "Accuracy:  0.961\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9778    0.9778    0.9778       496\n",
      "         2.0     0.9624    0.9788    0.9705       471\n",
      "         3.0     0.9976    0.9810    0.9892       420\n",
      "         4.0     0.9650    0.8982    0.9304       491\n",
      "         5.0     0.8821    0.9699    0.9239       532\n",
      "         6.0     1.0000    0.9628    0.9810       537\n",
      "\n",
      "    accuracy                         0.9610      2947\n",
      "   macro avg     0.9641    0.9614    0.9621      2947\n",
      "weighted avg     0.9628    0.9610    0.9612      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.RidgeClassifier(\n",
    "    solver='lsqr',\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "ridge.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_ridge = ridge.predict(X_train_pca)\n",
    "preds_test_ridge = ridge.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_ridge, test_print_ridge, train_array_ridge, test_array_ridge = metrics_extraction(\n",
    "    preds_train_ridge, preds_test_ridge, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_ridge, '-'*25, sep='\\n')\n",
    "print(*test_print_ridge, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_ridge, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier\n",
    "\n",
    "Попробуем подобрать оптимальную loss-функцию к стохастическому градиентному спуску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9879\n",
      "Recall:    0.9879\n",
      "F1 score:  0.9879\n",
      "Accuracy:  0.9879\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9527\n",
      "Recall:    0.9511\n",
      "F1 score:  0.9513\n",
      "Accuracy:  0.9511\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9716    0.9657    0.9687       496\n",
      "         2.0     0.9498    0.9639    0.9568       471\n",
      "         3.0     0.9618    0.9595    0.9607       420\n",
      "         4.0     0.9561    0.8880    0.9208       491\n",
      "         5.0     0.8797    0.9624    0.9192       532\n",
      "         6.0     1.0000    0.9665    0.9830       537\n",
      "\n",
      "    accuracy                         0.9511      2947\n",
      "   macro avg     0.9532    0.9510    0.9515      2947\n",
      "weighted avg     0.9527    0.9511    0.9513      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация объекта\n",
    "sgdc = linear_model.SGDClassifier(\n",
    "    loss='perceptron',\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "sgdc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "sgdc_preds_train = sgdc.predict(X_train_pca)\n",
    "sgdc_preds_test = sgdc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_sgdc, test_print_sgdc, train_array_sgdc, test_array_sgdc = metrics_extraction(\n",
    "    sgdc_preds_train, sgdc_preds_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_sgdc, '-'*25, sep='\\n')\n",
    "print(*test_print_sgdc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, sgdc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не стали включать в работу оптимизированный с помощью optuna алгоритм, т.к. нам не удалось подобрать с ним такие параметры, что показали бы лучший результат чем тот, что мы имеем в варианте с указанием лишь loss-функции: линейные потери, используемые алгоритмом перцептрона, в нашем кейсе минимизируются алгоритмом SGD эффективнее прочих. Базовая модель все же преодолена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9716\n",
      "Recall:    0.9705\n",
      "F1 score:  0.9703\n",
      "Accuracy:  0.9705\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9859    0.9859    0.9859       496\n",
      "         2.0     0.9769    0.9873    0.9820       471\n",
      "         3.0     0.9904    0.9810    0.9856       420\n",
      "         4.0     0.9797    0.8839    0.9293       491\n",
      "         5.0     0.9064    0.9831    0.9432       532\n",
      "         6.0     0.9963    1.0000    0.9981       537\n",
      "\n",
      "    accuracy                         0.9705      2947\n",
      "   macro avg     0.9726    0.9702    0.9707      2947\n",
      "weighted avg     0.9716    0.9705    0.9703      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация объекта\n",
    "mlpc = neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(166, 36),\n",
    "    activation='tanh',\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "mlpc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "mlpc_preds_train = mlpc.predict(X_train_pca)\n",
    "mlpc_preds_test = mlpc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_mlpc, test_print_mlpc, train_array_mlpc, test_array_mlpc = metrics_extraction(\n",
    "    mlpc_preds_train, mlpc_preds_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_mlpc, '-'*25, sep='\\n')\n",
    "print(*test_print_mlpc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, mlpc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ходьба</th>\n",
       "      <th>подъём</th>\n",
       "      <th>спуск</th>\n",
       "      <th>сидение</th>\n",
       "      <th>стояние</th>\n",
       "      <th>лежание</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ходьба</th>\n",
       "      <td>489</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>подъём</th>\n",
       "      <td>5</td>\n",
       "      <td>465</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>спуск</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сидение</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>стояние</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>лежание</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ходьба  подъём  спуск  сидение  стояние  лежание\n",
       "ходьба      489       4      3        0        0        0\n",
       "подъём        5     465      1        0        0        0\n",
       "спуск         2       6    412        0        0        0\n",
       "сидение       0       1      0      434       54        2\n",
       "стояние       0       0      0        9      523        0\n",
       "лежание       0       0      0        0        0      537"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаём таблицу сопряжённости\n",
    "ct = pd.crosstab(y_test, mlpc_preds_test)\n",
    "# определяем название активностей\n",
    "ct.index = ['ходьба', 'подъём', \n",
    "            'спуск', 'сидение',\n",
    "            'стояние', 'лежание'\n",
    "]\n",
    "ct.columns = list(ct.index)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм однозначно переобучен, но на данный момент демонстрирует наилучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9977\n",
      "Recall:    0.9977\n",
      "F1 score:  0.9977\n",
      "Accuracy:  0.9977\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9614\n",
      "Recall:    0.9606\n",
      "F1 score:  0.9605\n",
      "Accuracy:  0.9606\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9916    0.9476    0.9691       496\n",
      "         2.0     0.9528    0.9851    0.9687       471\n",
      "         3.0     0.9833    0.9833    0.9833       420\n",
      "         4.0     0.9452    0.8778    0.9102       491\n",
      "         5.0     0.9069    0.9699    0.9373       532\n",
      "         6.0     0.9926    1.0000    0.9963       537\n",
      "\n",
      "    accuracy                         0.9606      2947\n",
      "   macro avg     0.9621    0.9606    0.9608      2947\n",
      "weighted avg     0.9614    0.9606    0.9605      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация объекта\n",
    "lin_svc = svm.LinearSVC(random_state=42)\n",
    "# Обучение\n",
    "lin_svc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "lin_svc_preds_train = lin_svc.predict(X_train_pca)\n",
    "lin_svc_preds_test = lin_svc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_lin_svc, test_print_lin_svc, train_array_lin_svc, test_array_lin_svc = metrics_extraction(\n",
    "    lin_svc_preds_train, lin_svc_preds_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_lin_svc, '-'*25, sep='\\n')\n",
    "print(*test_print_lin_svc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, lin_svc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9966\n",
      "Recall:    0.9966\n",
      "F1 score:  0.9966\n",
      "Accuracy:  0.9966\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9622\n",
      "Recall:    0.962\n",
      "F1 score:  0.9619\n",
      "Accuracy:  0.962\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9778    0.9758    0.9768       496\n",
      "         2.0     0.9583    0.9766    0.9674       471\n",
      "         3.0     0.9807    0.9667    0.9736       420\n",
      "         4.0     0.9444    0.9002    0.9218       491\n",
      "         5.0     0.9150    0.9511    0.9327       532\n",
      "         6.0     1.0000    1.0000    1.0000       537\n",
      "\n",
      "    accuracy                         0.9620      2947\n",
      "   macro avg     0.9627    0.9617    0.9621      2947\n",
      "weighted avg     0.9622    0.9620    0.9619      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация объекта\n",
    "svc = svm.SVC(\n",
    "    kernel='linear',\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "svc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "svc_preds_train = svc.predict(X_train_pca)\n",
    "svc_preds_test = svc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_svc, test_print_svc, train_array_svc, test_array_svc = metrics_extraction(\n",
    "    svc_preds_train, svc_preds_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_svc, '-'*25, sep='\\n')\n",
    "print(*test_print_svc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, svc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также оптимизировать алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'C': 0.6717891413252985, 'kernel': 'linear', 'gamma': 'auto', 'decision_function_shape': 'ovo'}\n",
      "f1_score на обучающем наборе: 0.9471\n",
      "\n",
      "Train aggregate metrics:\n",
      "Precision: 0.9958\n",
      "Recall:    0.9958\n",
      "F1 score:  0.9958\n",
      "Accuracy:  0.9958\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9636\n",
      "Recall:    0.9634\n",
      "F1 score:  0.9633\n",
      "Accuracy:  0.9634\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9778    0.9758    0.9768       496\n",
      "         2.0     0.9583    0.9766    0.9674       471\n",
      "         3.0     0.9807    0.9667    0.9736       420\n",
      "         4.0     0.9468    0.9063    0.9261       491\n",
      "         5.0     0.9201    0.9530    0.9363       532\n",
      "         6.0     1.0000    1.0000    1.0000       537\n",
      "\n",
      "    accuracy                         0.9634      2947\n",
      "   macro avg     0.9640    0.9631    0.9634      2947\n",
      "weighted avg     0.9636    0.9634    0.9633      2947\n",
      "\n",
      "CPU times: total: 1.12 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Напишем функцию для оптимизации\n",
    "def optuna_SVC(trial):\n",
    "    \"\"\"Функция, обучающая модель LogisticRegression по переданным гиперпараметрам\n",
    "    Args:\n",
    "        trial : класс, от которого вызываются гиперпараметры\n",
    "    Returns:\n",
    "        score(float): метрика F1\n",
    "    \"\"\"\n",
    "    # Задаем пространство поиска гиперпараметров\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 0.01, 20),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf', 'linear']),\n",
    "        'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "        'coef0': trial.suggest_float('C', 0, 1),\n",
    "        'decision_function_shape': trial.suggest_categorical('decision_function_shape', ['ovo', 'ovr'])\n",
    "    }\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = svm.SVC(\n",
    "        **params,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Рассчитываем метрику на кросс-валидации\n",
    "    score = model_selection.cross_val_score(\n",
    "        model, X_train_pca, y_train, cv=10, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "    return score\n",
    "\n",
    "# Создаем объект исследования для первого набора гиперпараметров\n",
    "# Укажем, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_SVC = optuna.create_study(study_name=\"SVC_opt\", direction=\"maximize\",)\n",
    "# Подавляем логирование\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_SVC.optimize(optuna_SVC, n_trials=20)\n",
    "\n",
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "opt_SVC = svm.SVC(\n",
    "    **study_SVC.best_params,\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "opt_SVC.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_opt_SVC = opt_SVC.predict(X_train_pca)\n",
    "preds_test_opt_SVC = opt_SVC.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_opt_SVC, test_print_opt_SVC, train_array_opt_SVC, test_array_opt_SVC = metrics_extraction(\n",
    "    preds_train_opt_SVC, preds_test_opt_SVC, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(f'Лучшие гиперпараметры: {study_SVC.best_params}')\n",
    "print(\"f1_score на обучающем наборе: {:.4f}\\n\".format(study_SVC.best_value))\n",
    "print(*train_print_opt_SVC, '-'*25, sep='\\n')\n",
    "print(*test_print_opt_SVC, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_opt_SVC, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось неслабо, идем дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 22, 'min_samples_leaf': 11}\n",
      "f1_score на обучающем наборе: 0.7704\n",
      "\n",
      "Train aggregate metrics:\n",
      "Precision: 0.8861\n",
      "Recall:    0.8852\n",
      "F1 score:  0.8854\n",
      "Accuracy:  0.8852\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.8003\n",
      "Recall:    0.7954\n",
      "F1 score:  0.7966\n",
      "Accuracy:  0.7954\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.7661    0.8649    0.8125       496\n",
      "         2.0     0.8447    0.7856    0.8141       471\n",
      "         3.0     0.7692    0.7143    0.7407       420\n",
      "         4.0     0.6667    0.7251    0.6946       491\n",
      "         5.0     0.7591    0.7462    0.7526       532\n",
      "         6.0     0.9801    0.9162    0.9471       537\n",
      "\n",
      "    accuracy                         0.7954      2947\n",
      "   macro avg     0.7976    0.7920    0.7936      2947\n",
      "weighted avg     0.8003    0.7954    0.7966      2947\n",
      "\n",
      "CPU times: total: 4.77 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Напишем функцию для перебора гиперпараметров\n",
    "def optuna_dtc(trial):\n",
    "    \"\"\"Функция, обучающая модель DecisionTreeClassifier по переданным гиперпараметрам\n",
    "    Args:\n",
    "        trial : класс, от которого вызываются гиперпараметры\n",
    "    Returns:\n",
    "        score(float): метрика F1\n",
    "    \"\"\"\n",
    "    # Задаем пространствао поиска гиперпараметров\n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 51, 2),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    }\n",
    "\n",
    "    # Создаем модель\n",
    "    model=tree.DecisionTreeClassifier(\n",
    "        **params,\n",
    "        random_state=42        \n",
    "    )   \n",
    "    # Рассчитаем метрику на кросс-валидации\n",
    "    score = model_selection.cross_val_score(\n",
    "        model, X_train_pca, y_train, cv=10, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Создаем объект исследования для первого набора гиперпараметров\n",
    "# Укажем, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_dtc = optuna.create_study(study_name=\"dtc_opt\", direction=\"maximize\")\n",
    "# Подавляем логирование\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_dtc.optimize(optuna_dtc, n_trials=20)\n",
    "\n",
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "opt_dtc = tree.DecisionTreeClassifier(**study_dtc.best_params, random_state=42)\n",
    "# Обучение\n",
    "opt_dtc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_opt_dtc = opt_dtc.predict(X_train_pca)\n",
    "preds_test_opt_dtc = opt_dtc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_opt_dtc, test_print_opt_dtc, train_array_opt_dtc, test_array_opt_dtc = metrics_extraction(\n",
    "    preds_train_opt_dtc, preds_test_opt_dtc, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(f'Лучшие гиперпараметры: {study_dtc.best_params}')\n",
    "print(\"f1_score на обучающем наборе: {:.4f}\\n\".format(study_dtc.best_value))\n",
    "print(*train_print_opt_dtc, '-'*25, sep='\\n')\n",
    "print(*test_print_opt_dtc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_opt_dtc, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У древесных алгоритмов, похоже, действительно проблемы с нашими данными: отставание классификатора Catboost имеет под собой принципиальное основание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.906\n",
      "Recall:    0.9046\n",
      "F1 score:  0.9041\n",
      "Accuracy:  0.9046\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.8872    0.9194    0.9030       496\n",
      "         2.0     0.9177    0.9236    0.9206       471\n",
      "         3.0     0.8635    0.8286    0.8457       420\n",
      "         4.0     0.9233    0.8086    0.8621       491\n",
      "         5.0     0.8508    0.9436    0.8948       532\n",
      "         6.0     0.9851    0.9832    0.9842       537\n",
      "\n",
      "    accuracy                         0.9046      2947\n",
      "   macro avg     0.9046    0.9011    0.9017      2947\n",
      "weighted avg     0.9060    0.9046    0.9041      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=475,\n",
    "    max_depth=42,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "rfc_preds_train = rfc.predict(X_train_pca)\n",
    "rfc_preds_test = rfc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_rfc, test_print_rfc, train_array_rfc, test_array_rfc = metrics_extraction(\n",
    "    rfc_preds_train, rfc_preds_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_rfc, '-'*25, sep='\\n')\n",
    "print(*test_print_rfc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, rfc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры были подобраны на optuna, весь процесс занял сорок минут времени, а результат все еще хуже, чем у линейных алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9984\n",
      "Recall:    0.9984\n",
      "F1 score:  0.9984\n",
      "Accuracy:  0.9984\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9232\n",
      "Recall:    0.9233\n",
      "F1 score:  0.9229\n",
      "Accuracy:  0.9233\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9111    0.9294    0.9202       496\n",
      "         2.0     0.9095    0.9597    0.9339       471\n",
      "         3.0     0.8966    0.8262    0.8600       420\n",
      "         4.0     0.9018    0.8982    0.9000       491\n",
      "         5.0     0.9134    0.9117    0.9125       532\n",
      "         6.0     0.9963    0.9963    0.9963       537\n",
      "\n",
      "    accuracy                         0.9233      2947\n",
      "   macro avg     0.9214    0.9202    0.9205      2947\n",
      "weighted avg     0.9232    0.9233    0.9229      2947\n",
      "\n",
      "CPU times: total: 21min 42s\n",
      "Wall time: 21min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Инициализация объекта\n",
    "gbc = ensemble.GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "gbc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "gbc_preds_train = gbc.predict(X_train_pca)\n",
    "gbc_preds_test = gbc.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_gbc, test_print_gbc, train_array_gbc, test_array_gbc = metrics_extraction(\n",
    "    gbc_preds_train, gbc_preds_test, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_gbc, '-'*25, sep='\\n')\n",
    "print(*test_print_gbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, gbc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуй, оптимизация градиентного бустинга займет довольно много времени тоже, рассмотрим лучше его модификацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9299\n",
      "Recall:    0.9294\n",
      "F1 score:  0.929\n",
      "Accuracy:  0.9294\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9178    0.9456    0.9315       496\n",
      "         2.0     0.9194    0.9682    0.9431       471\n",
      "         3.0     0.9217    0.8405    0.8792       420\n",
      "         4.0     0.9208    0.8758    0.8977       491\n",
      "         5.0     0.8984    0.9474    0.9222       532\n",
      "         6.0     0.9962    0.9814    0.9887       537\n",
      "\n",
      "    accuracy                         0.9294      2947\n",
      "   macro avg     0.9290    0.9265    0.9271      2947\n",
      "weighted avg     0.9299    0.9294    0.9290      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgbc = ensemble.HistGradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "hgbc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "hgbc_preds_train = hgbc.predict(X_train_pca)\n",
    "hgbc_preds_test = hgbc.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_hgbc, test_print_hgbc, train_array_hgbc, test_array_hgbc = metrics_extraction(\n",
    "    hgbc_preds_train, hgbc_preds_test, y_train, y_test\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_hgbc, '-'*25, sep='\\n')\n",
    "print(*test_print_hgbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, hgbc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'learning_rate': 0.5946483853506327, 'max_leaf_nodes': 2, 'max_depth': 30, 'min_samples_leaf': 29, 'l2_regularization': 0.6127862016309231}\n",
      "f1_score на обучающем наборе: 0.9231\n",
      "\n",
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9525\n",
      "Recall:    0.9525\n",
      "F1 score:  0.9523\n",
      "Accuracy:  0.9525\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9660    0.9738    0.9699       496\n",
      "         2.0     0.9599    0.9660    0.9630       471\n",
      "         3.0     0.9500    0.9500    0.9500       420\n",
      "         4.0     0.9312    0.8819    0.9059       491\n",
      "         5.0     0.9144    0.9436    0.9288       532\n",
      "         6.0     0.9926    0.9963    0.9944       537\n",
      "\n",
      "    accuracy                         0.9525      2947\n",
      "   macro avg     0.9523    0.9519    0.9520      2947\n",
      "weighted avg     0.9525    0.9525    0.9523      2947\n",
      "\n",
      "CPU times: total: 14.5 s\n",
      "Wall time: 1h 12min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Напишем функцию для перебора гиперпараметров\n",
    "def optuna_hgbc(trial):\n",
    "    \"\"\"Функция, обучающая модель HistGradientBoostingClassifier по переданным гиперпараметрам\n",
    "    Args:\n",
    "        trial : класс, от которого вызываются гиперпараметры\n",
    "    Returns:\n",
    "        score(float): метрика F1\n",
    "    \"\"\"\n",
    "    # Задаем пространствао поиска гиперпараметров\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 50, 2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 30, 1),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 3, 101, 2),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0, 1)\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Создаем модель\n",
    "    model=ensemble.HistGradientBoostingClassifier(\n",
    "        **params,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Рассчитаем метрику на кросс-валидации\n",
    "    score = model_selection.cross_val_score(\n",
    "        model, X_train_pca, y_train, cv=10, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Создаем объект исследования для первого набора гиперпараметров\n",
    "# Укажем, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_hgbc = optuna.create_study(study_name=\"hgbc_opt\", direction=\"maximize\")\n",
    "# Подавляем логирование\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_hgbc.optimize(optuna_hgbc, n_trials=50)\n",
    "\n",
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "opt_hgbc = ensemble.HistGradientBoostingClassifier(\n",
    "    **study_hgbc.best_params,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "# Обучение\n",
    "opt_hgbc.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_opt_hgbc = opt_hgbc.predict(X_train_pca)\n",
    "preds_test_opt_hgbc = opt_hgbc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_opt_hgbc, test_print_opt_hgbc, train_array_opt_hgbc, test_array_opt_hgbc = metrics_extraction(\n",
    "    preds_train_opt_hgbc, preds_test_opt_hgbc, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(f'Лучшие гиперпараметры: {study_hgbc.best_params}')\n",
    "print(\"f1_score на обучающем наборе: {:.4f}\\n\".format(study_hgbc.best_value))\n",
    "print(*train_print_opt_hgbc, '-'*25, sep='\\n')\n",
    "print(*test_print_opt_hgbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_opt_hgbc, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация шла более часа, но оно того стоило."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 score:  1.0\n",
      "Accuracy:  1.0\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9266\n",
      "Recall:    0.9264\n",
      "F1 score:  0.9259\n",
      "Accuracy:  0.9264\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9150    0.9335    0.9242       496\n",
      "           1     0.9157    0.9682    0.9412       471\n",
      "           2     0.9115    0.8333    0.8706       420\n",
      "           3     0.9188    0.8758    0.8968       491\n",
      "           4     0.8961    0.9398    0.9174       532\n",
      "           5     0.9962    0.9888    0.9925       537\n",
      "\n",
      "    accuracy                         0.9264      2947\n",
      "   macro avg     0.9255    0.9232    0.9238      2947\n",
      "weighted avg     0.9266    0.9264    0.9259      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.fit_transform(y_test)\n",
    "\n",
    "xgbc = xgb.XGBClassifier()\n",
    "# Обучение\n",
    "xgbc.fit(X_train_pca, y_train_le)\n",
    "# Предсказания\n",
    "xgbc_preds_train = xgbc.predict(X_train_pca)\n",
    "xgbc_preds_test = xgbc.predict(X_test_pca)\n",
    "# Получение метрик\n",
    "train_print_xgbc, test_print_xgbc, train_array_xgbc, test_array_xgbc = metrics_extraction(\n",
    "    xgbc_preds_train, xgbc_preds_test, y_train_le, y_test_le\n",
    ")\n",
    "# Вывод метрик\n",
    "print(*train_print_xgbc, '-'*25, sep='\\n')\n",
    "print(*test_print_xgbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test_le, xgbc_preds_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'max_depth': 15, 'gamma': 1.056683066713876, 'reg_alpha': 41, 'reg_lambda': 0.838433409752353, 'colsample_bytree': 0.9402579732543315, 'min_child_weight': 8, 'n_estimators': 300}\n",
      "f1_score на обучающем наборе: 0.8420\n",
      "\n",
      "Train aggregate metrics:\n",
      "Precision: 0.9538\n",
      "Recall:    0.9538\n",
      "F1 score:  0.9536\n",
      "Accuracy:  0.9538\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.8845\n",
      "Recall:    0.8843\n",
      "F1 score:  0.8831\n",
      "Accuracy:  0.8843\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8505    0.9173    0.8826       496\n",
      "           1     0.8735    0.9236    0.8978       471\n",
      "           2     0.8520    0.7262    0.7841       420\n",
      "           3     0.8723    0.8208    0.8458       491\n",
      "           4     0.8523    0.9004    0.8757       532\n",
      "           5     0.9944    0.9851    0.9897       537\n",
      "\n",
      "    accuracy                         0.8843      2947\n",
      "   macro avg     0.8825    0.8789    0.8793      2947\n",
      "weighted avg     0.8845    0.8843    0.8831      2947\n",
      "\n",
      "CPU times: total: 1min 1s\n",
      "Wall time: 18min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Напишем функцию для перебора гиперпараметров\n",
    "def optuna_xgbc(trial):\n",
    "    \"\"\"Функция, обучающая модель XGBClassifier по переданным гиперпараметрам\n",
    "    Args:\n",
    "        trial : класс, от которого вызываются гиперпараметры\n",
    "    Returns:\n",
    "        score(float): метрика F1\n",
    "    \"\"\"\n",
    "    # Задаем пространствао поиска гиперпараметров\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 18, 1),\n",
    "        'gamma': trial.suggest_float('gamma', 1, 9),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 40, 180, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1001, 25)\n",
    "    }\n",
    "\n",
    "    # Создаем модель\n",
    "    model=xgb.XGBClassifier(\n",
    "        **params,\n",
    "        seed=42\n",
    "    )\n",
    "    # Рассчитаем метрику на кросс-валидации\n",
    "    score = model_selection.cross_val_score(\n",
    "        model, X_train_pca, y_train_le, cv=10, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "    return score\n",
    "\n",
    "# Создаем объект исследования для первого набора гиперпараметров\n",
    "# Укажем, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_xgbc = optuna.create_study(study_name=\"xgbc_opt\", direction=\"maximize\")\n",
    "# Подавляем логирование\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_xgbc.optimize(optuna_xgbc, n_trials=30)\n",
    "\n",
    "# Передаем модели коллекцию оптимальных гиперпараметров\n",
    "opt_xgbc = xgb.XGBClassifier(**study_xgbc.best_params)\n",
    "# Обучение\n",
    "opt_xgbc.fit(X_train_pca, y_train_le)\n",
    "# Предсказания\n",
    "preds_train_opt_xgbc = opt_xgbc.predict(X_train_pca)\n",
    "preds_test_opt_xgbc = opt_xgbc.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_opt_xgbc, test_print_opt_xgbc, train_array_opt_xgbc, test_array_opt_xgbc = metrics_extraction(\n",
    "    preds_train_opt_xgbc, preds_test_opt_xgbc, y_train_le, y_test_le\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(f'Лучшие гиперпараметры: {study_xgbc.best_params}')\n",
    "print(\"f1_score на обучающем наборе: {:.4f}\\n\".format(study_xgbc.best_value))\n",
    "print(*train_print_opt_xgbc, '-'*25, sep='\\n')\n",
    "print(*test_print_opt_xgbc, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test_le, preds_test_opt_xgbc, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, оптимизатор и на этот раз застрял в локальном минимуме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregate metrics:\n",
      "Precision: 0.9934\n",
      "Recall:    0.9933\n",
      "F1 score:  0.9933\n",
      "Accuracy:  0.9933\n",
      "-------------------------\n",
      "Test aggregate metrics:\n",
      "Precision: 0.9722\n",
      "Recall:    0.9715\n",
      "F1 score:  0.9714\n",
      "Accuracy:  0.9715\n",
      "-------------------------\n",
      "Full test metrics report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9818    0.9778    0.9798       496\n",
      "         2.0     0.9788    0.9788    0.9788       471\n",
      "         3.0     0.9905    0.9976    0.9941       420\n",
      "         4.0     0.9714    0.9002    0.9345       491\n",
      "         5.0     0.9153    0.9756    0.9445       532\n",
      "         6.0     1.0000    1.0000    1.0000       537\n",
      "\n",
      "    accuracy                         0.9715      2947\n",
      "   macro avg     0.9730    0.9717    0.9719      2947\n",
      "weighted avg     0.9722    0.9715    0.9714      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Список моделей для стэка\n",
    "estimators = [\n",
    "    ('log_reg', LogR_opt),\n",
    "    ('pac', pac),\n",
    "    ('ridge', ridge),\n",
    "    ('mlpc', mlpc),\n",
    "    ('lin_svc', lin_svc),\n",
    "    ('opt_SVC', opt_SVC)\n",
    "]\n",
    "# Инициализация объекта\n",
    "sc_metamodel = ensemble.StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=linear_model.LogisticRegression(\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Обучение\n",
    "sc_metamodel.fit(X_train_pca, y_train)\n",
    "# Предсказания\n",
    "preds_train_scmm = sc_metamodel.predict(X_train_pca)\n",
    "preds_test_scmm = sc_metamodel.predict(X_test_pca)\n",
    "\n",
    "# Получение метрик\n",
    "train_print_scmm, test_print_scmm, train_array_scmm, test_array_scmm = metrics_extraction(\n",
    "    preds_train_scmm, preds_test_scmm, y_train, y_test\n",
    ")\n",
    "\n",
    "# Вывод метрик\n",
    "print(*train_print_scmm, '-'*25, sep='\\n')\n",
    "print(*test_print_scmm, '-'*25, sep='\\n')\n",
    "print('Full test metrics report:')\n",
    "print(metrics.classification_report(y_test, preds_test_scmm, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "\n",
    "Проведем стекинг-алгоритм через кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores:\n",
      "Precision:   0.9983\n",
      "Recall:      0.9983\n",
      "F1 weighted: 0.9983\n",
      "Accuracy:    0.9983\n",
      "Test scores:\n",
      "Precision:   0.9671\n",
      "Recall:      0.9638\n",
      "F1 weighted: 0.9635\n",
      "Accuracy:    0.9638\n"
     ]
    }
   ],
   "source": [
    "cv_scores(sc_metamodel, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также проведем через кросс-валидацию каждую из моделей из состава стекинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=0.7630868925337111, max_iter=3000, n_jobs=-1,\n",
      "                   random_state=42, solver='newton-cholesky')\n",
      "Train scores:\n",
      "Precision:   0.9934\n",
      "Recall:      0.9934\n",
      "F1 weighted: 0.9934\n",
      "Accuracy:    0.9934\n",
      "Test scores:\n",
      "Precision:   0.9652\n",
      "Recall:      0.9615\n",
      "F1 weighted: 0.9612\n",
      "Accuracy:    0.9615\n",
      "--------------------\n",
      "Model: PassiveAggressiveClassifier(random_state=42)\n",
      "Train scores:\n",
      "Precision:   0.9887\n",
      "Recall:      0.9885\n",
      "F1 weighted: 0.9885\n",
      "Accuracy:    0.9885\n",
      "Test scores:\n",
      "Precision:   0.9608\n",
      "Recall:      0.9569\n",
      "F1 weighted: 0.9568\n",
      "Accuracy:    0.9569\n",
      "--------------------\n",
      "Model: RidgeClassifier(random_state=42, solver='lsqr')\n",
      "Train scores:\n",
      "Precision:   0.9813\n",
      "Recall:      0.9813\n",
      "F1 weighted: 0.9813\n",
      "Accuracy:    0.9813\n",
      "Test scores:\n",
      "Precision:   0.9612\n",
      "Recall:      0.9582\n",
      "F1 weighted: 0.958\n",
      "Accuracy:    0.9582\n",
      "--------------------\n",
      "Model: MLPClassifier(activation='tanh', hidden_layer_sizes=(166, 36), random_state=42)\n",
      "Train scores:\n",
      "Precision:   1.0\n",
      "Recall:      1.0\n",
      "F1 weighted: 1.0\n",
      "Accuracy:    1.0\n",
      "Test scores:\n",
      "Precision:   0.9676\n",
      "Recall:      0.9642\n",
      "F1 weighted: 0.9639\n",
      "Accuracy:    0.9642\n",
      "--------------------\n",
      "Model: LinearSVC(random_state=42)\n",
      "Train scores:\n",
      "Precision:   0.9962\n",
      "Recall:      0.9961\n",
      "F1 weighted: 0.9961\n",
      "Accuracy:    0.9961\n",
      "Test scores:\n",
      "Precision:   0.9626\n",
      "Recall:      0.9588\n",
      "F1 weighted: 0.9587\n",
      "Accuracy:    0.9588\n",
      "--------------------\n",
      "Model: SVC(C=0.6717891413252985, decision_function_shape='ovo', gamma='auto',\n",
      "    kernel='linear', random_state=42)\n",
      "Train scores:\n",
      "Precision:   0.9958\n",
      "Recall:      0.9958\n",
      "F1 weighted: 0.9958\n",
      "Accuracy:    0.9958\n",
      "Test scores:\n",
      "Precision:   0.9638\n",
      "Recall:      0.9607\n",
      "F1 weighted: 0.9605\n",
      "Accuracy:    0.9607\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "models = [LogR_opt, pac, ridge, mlpc, lin_svc, opt_SVC]\n",
    "\n",
    "for model in models:\n",
    "    print(f'Model: {model}')\n",
    "    cv_scores(model, X, y)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат продемонстрировал MLPClassifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
